{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agentchat_web_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Auto Generated Agent Chat: Solving Tasks Requiring Web Info\n",
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/FLAML/docs/Use-Cases/Auto-Generation#agents-experimental).\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to perform tasks which require acquiring info from the web:\n",
    "* discuss a paper based on its URL.\n",
    "* discuss about stock market.\n",
    "\n",
    "Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"TERMINATE\", the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`, and prompt the user for feedback when the task is finished. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]~=2.0.0rc4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import oai\n",
    "\n",
    "config_list = oai.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the models with matching names are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k-0314',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent. We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for human feedback when it receives a \"TERMINATE\" signal from the assistant agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    oai_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "        \"model\": \"gpt-4-32k\",  # modify if the endpoint you use doesn't support this model\n",
    "        \"temperature\": 0,\n",
    "    }\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\"work_dir\": \"web\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Paper Talk from URL\n",
    "\n",
    "We invoke the `initiate_chat()` method of the user proxy agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after the assistant agent sends a \"TERMINATE\" signal in the end of the message. If you don't provide any feedback (by pressing Enter directly), the conversation will finish. Before the \"TERMINATE\" signal, the user proxy agent will try to execute the code suggested by the assistant agent on behalf of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_proxy (to assistant):\n",
      "\n",
      "\n",
      "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "To determine who should read this paper, let's first extract the abstract and analyze its content. We can use Python with the `requests` and `BeautifulSoup` libraries to do this. Please execute the following code:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = \"https://arxiv.org/abs/2306.01337\"\n",
      "response = requests.get(url)\n",
      "soup = BeautifulSoup(response.text, \"html.parser\")\n",
      "abstract = soup.find(\"blockquote\", {\"class\": \"abstract\"}).text.strip()\n",
      "print(abstract)\n",
      "```\n",
      "\n",
      "After executing the code, I will analyze the abstract and suggest who should read the paper.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_proxy (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Abstract:  Employing Large Language Models (LLMs) to address mathematical problems is an\n",
      "intriguing research endeavor, considering the abundance of math problems\n",
      "expressed in natural language across numerous science and engineering fields.\n",
      "While several prior works have investigated solving elementary mathematics\n",
      "using LLMs, this work explores the frontier of using GPT-4 for solving more\n",
      "complex and challenging math problems. We evaluate various ways of using GPT-4.\n",
      "Some of them are adapted from existing work, and one is MathChat, a\n",
      "conversational problem-solving framework newly proposed in this work. We\n",
      "perform the evaluation on difficult high school competition problems from the\n",
      "MATH dataset, which shows the advantage of the proposed conversational\n",
      "approach.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "Based on the abstract, the paper is about using Large Language Models (LLMs), specifically GPT-4, to solve complex mathematical problems. The authors propose a conversational problem-solving framework called MathChat and evaluate it on difficult high school competition problems from the MATH dataset.\n",
      "\n",
      "The target audience for this paper includes:\n",
      "\n",
      "1. Researchers and practitioners in the field of artificial intelligence, specifically those working with large language models like GPT-4.\n",
      "2. Mathematicians and educators interested in the application of AI for solving complex mathematical problems.\n",
      "3. Developers working on AI-based conversational systems or chatbots for problem-solving in various domains.\n",
      "4. Students and researchers in natural language processing, machine learning, and AI who are interested in the intersection of these fields with mathematics.\n",
      "\n",
      "If you belong to any of these categories or have a general interest in AI and its applications, you might find this paper valuable. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"\n",
    "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Chat about Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_proxy (to assistant):\n",
      "\n",
      "Show me the YTD gain of 10 largest technology companies as of today.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "To get the YTD gain of the 10 largest technology companies, we can use a Python script to fetch the data from a financial API like Yahoo Finance. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import requests\n",
      "import pandas as pd\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_top_tech_companies():\n",
      "    url = \"https://www.tradingview.com/markets/stocks-usa/sectorandindustry-industry/technology/\"\n",
      "    response = requests.get(url)\n",
      "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
      "    table = soup.find(\"table\", {\"class\": \"tv-data-table\"})\n",
      "    rows = table.find_all(\"tr\")[1:11]\n",
      "    symbols = [row.find(\"a\").text for row in rows]\n",
      "    return symbols\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    today = datetime.date.today()\n",
      "    start_date = datetime.date(today.year, 1, 1)\n",
      "    url = f\"https://query1.finance.yahoo.com/v7/finance/download/{symbol}?period1={int(start_date.timestamp())}&period2={int(today.timestamp())}&interval=1d&events=history&includeAdjustedClose=true\"\n",
      "    response = requests.get(url)\n",
      "    data = pd.read_csv(pd.StringIO(response.text))\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "    return ytd_gain\n",
      "\n",
      "top_tech_companies = get_top_tech_companies()\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    print(f\"{symbol}: {gain:.2f}%\")\n",
      "```\n",
      "\n",
      "This code will fetch the 10 largest technology companies from TradingView and then calculate their YTD gains using Yahoo Finance data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_2e1e4c6201cb82d42fbeb0754e008d0f.py\", line 24, in <module>\n",
      "    top_tech_companies = get_top_tech_companies()\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_2e1e4c6201cb82d42fbeb0754e008d0f.py\", line 11, in get_top_tech_companies\n",
      "    rows = table.find_all(\"tr\")[1:11]\n",
      "AttributeError: 'NoneType' object has no attribute 'find_all'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I apologize for the error. It seems that the website structure has changed, and the script is unable to find the table containing the top technology companies. Let's try an alternative approach using the Yahoo Finance library. Please install the library first by executing:\n",
      "\n",
      "```sh\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "After installing the library, please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"FB\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    today = datetime.date.today()\n",
      "    start_date = datetime.date(today.year, 1, 1)\n",
      "    stock = yf.Ticker(symbol)\n",
      "    data = stock.history(start=start_date, end=today)\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "    return ytd_gain\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    print(f\"{symbol}: {gain:.2f}%\")\n",
      "```\n",
      "\n",
      "This code uses a predefined list of the 10 largest technology companies and calculates their YTD gains using the Yahoo Finance library.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /home/vscode/.local/lib/python3.9/site-packages (0.2.26)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2022.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.25.1)\n",
      "Requirement already satisfied: html5lib>=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.9/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/vscode/.local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vscode/.local/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.2.0)\n",
      "\n",
      "FB: No timezone found, symbol may be delisted\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 16, in <module>\n",
      "    ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 16, in <dictcomp>\n",
      "    ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 13, in get_ytd_gain\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1103, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1656, in _getitem_axis\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1589, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I apologize for the error. It seems that there is an issue with the data for the \"FB\" symbol. Let's add a try-except block to handle this issue. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"FB\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    try:\n",
      "        today = datetime.date.today()\n",
      "        start_date = datetime.date(today.year, 1, 1)\n",
      "        stock = yf.Ticker(symbol)\n",
      "        data = stock.history(start=start_date, end=today)\n",
      "        ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "        return ytd_gain\n",
      "    except Exception as e:\n",
      "        print(f\"Error fetching data for {symbol}: {e}\")\n",
      "        return None\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    if gain is not None:\n",
      "        print(f\"{symbol}: {gain:.2f}%\")\n",
      "    else:\n",
      "        print(f\"{symbol}: Data not available\")\n",
      "```\n",
      "\n",
      "This code will handle any issues with the data and display \"Data not available\" for any symbols that encounter an error.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Error fetching data for FB: single positional indexer is out-of-bounds\n",
      "AAPL: 55.26%\n",
      "MSFT: 47.19%\n",
      "GOOGL: 37.13%\n",
      "GOOG: 36.89%\n",
      "AMZN: 50.47%\n",
      "FB: Data not available\n",
      "TSLA: 145.40%\n",
      "NVDA: 219.19%\n",
      "ASML: 25.70%\n",
      "ADBE: 55.92%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I'm glad the code executed successfully. Here are the YTD gains for the 10 largest technology companies as of today:\n",
      "\n",
      "- AAPL: 55.26%\n",
      "- MSFT: 47.19%\n",
      "- GOOGL: 37.13%\n",
      "- GOOG: 36.89%\n",
      "- AMZN: 50.47%\n",
      "- FB: Data not available\n",
      "- TSLA: 145.40%\n",
      "- NVDA: 219.19%\n",
      "- ASML: 25.70%\n",
      "- ADBE: 55.92%\n",
      "\n",
      "Please note that the data for \"FB\" is not available due to an issue with the data source. You may want to check an alternative data source or try again later for the \"FB\" symbol.\n",
      "\n",
      "If you have any other questions or need further assistance, feel free to ask. Otherwise, if everything is done, please type \"TERMINATE\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "It seems you didn't provide any input. If you have any other questions or need further assistance, feel free to ask. Otherwise, if everything is done, please type \"TERMINATE\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I understand that you might be busy or have no further questions. If you need any assistance in the future, feel free to ask. Have a great day!\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "user_proxy (to assistant):\n",
      "\n",
      "FB -> META\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I apologize for the confusion earlier. The \"FB\" symbol has been changed to \"META\" due to the company's rebranding. Let's update the code with the new symbol and execute it again. Please run the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"META\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    try:\n",
      "        today = datetime.date.today()\n",
      "        start_date = datetime.date(today.year, 1, 1)\n",
      "        stock = yf.Ticker(symbol)\n",
      "        data = stock.history(start=start_date, end=today)\n",
      "        ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "        return ytd_gain\n",
      "    except Exception as e:\n",
      "        print(f\"Error fetching data for {symbol}: {e}\")\n",
      "        return None\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    if gain is not None:\n",
      "        print(f\"{symbol}: {gain:.2f}%\")\n",
      "    else:\n",
      "        print(f\"{symbol}: Data not available\")\n",
      "```\n",
      "\n",
      "This code will now use the \"META\" symbol instead of \"FB\" and should provide the YTD gain for Meta Platforms Inc. (formerly Facebook).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "AAPL: 55.26%\n",
      "MSFT: 47.19%\n",
      "GOOGL: 37.13%\n",
      "GOOG: 36.89%\n",
      "AMZN: 50.47%\n",
      "META: 136.07%\n",
      "TSLA: 145.40%\n",
      "NVDA: 219.19%\n",
      "ASML: 25.70%\n",
      "ADBE: 55.92%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "Great! The code executed successfully, and here are the updated YTD gains for the 10 largest technology companies as of today:\n",
      "\n",
      "- AAPL: 55.26%\n",
      "- MSFT: 47.19%\n",
      "- GOOGL: 37.13%\n",
      "- GOOG: 36.89%\n",
      "- AMZN: 50.47%\n",
      "- META: 136.07% (formerly FB)\n",
      "- TSLA: 145.40%\n",
      "- NVDA: 219.19%\n",
      "- ASML: 25.70%\n",
      "- ADBE: 55.92%\n",
      "\n",
      "If you have any other questions or need further assistance, feel free to ask. Otherwise, if everything is done, please type \"TERMINATE\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "It seems you didn't provide any input. If you have any other questions or need further assistance, feel free to ask. Otherwise, if everything is done, please type \"TERMINATE\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY FOR THE USER...\n",
      "user_proxy (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user_proxy):\n",
      "\n",
      "I understand that you might be busy or have no further questions. If you need any assistance in the future, feel free to ask. Have a great day!\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# it is suggested to reset the assistant to clear the state if the new task is not related to the previous one.\n",
    "assistant.reset()\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Show me the YTD gain of 10 largest technology companies as of today.\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
