{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatting with TeachableAgent\n",
    "\n",
    "Conversational assistants based on LLMs can remember the current chat with the user, and can even demonstrate in-context learning of things that the user teaches the assistant during the chat. But these memories and learnings are lost once the chat is over, or when a single chat grows too long for the LLM to handle effectively. In subsequent chats, the user is forced to repeat any necessary instructions over and over.\n",
    "\n",
    "`TeachableAgent` addresses these limitations by persisting user teachings across chat boundaries in long-term memory (a vector database). Memory is saved to disk at the end of each chat, then loaded from disk at the start of the next. Instead of copying all of memory into the context window, which would eat up valuable space, individual memories (called memos) are retrieved into context as needed. This allows the user to teach frequently used facts and skills to the agent just once, and have the agent remember them in later chats.\n",
    "\n",
    "In making decisions about memo storage and retrieval, `TeachableAgent` calls an instance of `TextAnalyzerAgent` to analyze pieces of text in several different ways. This adds extra LLM calls involving a relatively small number of tokens. These calls can add a few seconds to the time a user waits for a response.\n",
    "\n",
    "This notebook demonstrates how `TeachableAgent` can learn facts, preferences, and skills from users. To chat with `TeachableAgent` yourself, run [chat_with_teachable_agent.py](../test/agentchat/chat_with_teachable_agent.py).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install the [teachable] option.\n",
    "```bash\n",
    "pip install \"pyautogen[teachable]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install \"pyautogen[teachable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"OAI_CONFIG_LIST\",\n",
    "    file_location=\"\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(config_list[0][\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). After application of this particular filter, only the gpt-4 models are kept.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways if you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "For this walkthrough, we start by resetting the agent's memory store. This deletes any memories from prior conversations that may be stored on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "CLEARING MEMORY\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.teachable_agent import TeachableAgent\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "\n",
    "llm_config = {\n",
    "    \"request_timeout\": 1000,\n",
    "    \"config_list\": config_list,\n",
    "}\n",
    "\n",
    "teach_config={\n",
    "    \"verbosity\": 1,  # 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\n",
    "    \"reset_db\": True,  # Set to True to start over with an empty database.\n",
    "    \"path_to_db_dir\": \"./tmp/notebook/teachable_agent_db\",  # Path to the directory where the database will be stored.\n",
    "    \"recall_threshold\": 1.5,  # Higher numbers allow more (but less relevant) memos to be recalled.\n",
    "}\n",
    "\n",
    "try:\n",
    "    from termcolor import colored\n",
    "except ImportError:\n",
    "    def colored(x, *args, **kwargs):\n",
    "        return x\n",
    "    \n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "agent = TeachableAgent(\n",
    "    name=\"agent\",\n",
    "    llm_config=llm_config,\n",
    "    teach_config=teach_config)\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    max_consecutive_auto_reply=0,        \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning new facts\n",
    "Let's teach the agent some facts it doesn't already know, since they are more recent than GPT-4's training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "Hi can you please explain fractions to me?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "Absolutely, I'd be happy to explain fractions.\n",
      "\n",
      "A fraction is a method of expressing a quantity by using a numerator and a denominator. It represents a part of a whole.\n",
      "\n",
      "1. The **numerator** is the number above the line or before the slash in a fraction. It represents the number of parts we have.\n",
      "\n",
      "2. The **denominator** is the number below the line or after the slash. It represents the total number of equal parts into which the whole is divided.\n",
      "\n",
      "For example, in the fraction 3/4, \n",
      "\n",
      "- 3 is the numerator, which means we have 3 parts\n",
      "- 4 is the denominator, which means the whole is divided into 4 parts\n",
      "\n",
      "So, 3/4 means we have 3 parts of a whole which is divided into 4 equal parts.\n",
      "\n",
      "A fraction can also be seen as a division operation â€“ the fraction 3/4 represents the division of 3 by 4, which yields 0.75 in decimal form. \n",
      "\n",
      "Some fractions can be simplified. This is usually the case when the numerator and denominator share common factors. For example, the fraction 4/8 can be simplified to 1/2 because 4 and 8 are both divisible by 4.\n",
      "\n",
      "Does this help clarify what fractions are for you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi can you please explain fractions to me?\"\n",
    "user.initiate_chat(agent, message=text, clear_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "I don't understand this! Actually I would understand math operators better if you could explain it using money\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "Absolutely, using real world examples like money can often make understanding fractions easier.\n",
      "\n",
      "Let's stick with the fraction 3/4 and think about it in terms of dollars (or any other unit of currency you prefer).\n",
      "\n",
      "1. Imagine you have a whole dollar. This whole dollar represents 1 in fraction terms.\n",
      "2. Now, let's say you have to divide this dollar evenly into 4 parts, because the denominator of our fraction is 4. Each of these parts would be 25 cents, because a dollar consists of 100 cents and 100 divided by 4 is 25.\n",
      "3. The fraction we are working with is 3/4, where 3 is the numerator, so we take 3 parts out of these 4 parts each worth 25 cents. So, we now have 75 cents.\n",
      "\n",
      "Thus, the fraction 3/4 in terms of money would be 75 cents of a whole dollar. Another way to think about it is that you have 3 quarters of a dollar.\n",
      "\n",
      "I hope this makes understanding fractions a bit easier! Let me know if you have any other questions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = \"I don't understand this! Actually I would understand math operators better if you could explain it using money\"\n",
    "user.initiate_chat(agent, message=text, clear_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\n",
      "REVIEWING CHAT FOR USER TEACHINGS TO REMEMBER\u001b[0m\n",
      "\u001b[92m\n",
      "INPUT-OUTPUT PAIR ADDED TO VECTOR DATABASE:\n",
      "  INPUT\n",
      "    Can you explain math operators to me using money? I think it'd help me understand better.\n",
      "  OUTPUT\n",
      "    I don't understand this! Actually I would understand math operators better if you could explain it using money\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.learn_from_user_feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Chat Session\n",
    "Let's end our first chat here. The following function needs to be called at the end of each chat, so that `TeachableAgent` can store what the user has taught it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to agent):\n",
      "\n",
      "Hi can you please explain exclusive OR to me?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[93m\n",
      "MEMOS APPENDED TO LAST USER MESSAGE...\n",
      "\n",
      "# Memories that might help\n",
      "- I don't understand this! Actually I would understand math operators better if you could explain it using money\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33magent\u001b[0m (to user):\n",
      "\n",
      "Certainly, I can explain the concept of Exclusive OR (XOR) using a money-based analogy.\n",
      "\n",
      "So, let's imagine you have two friends, Alice and Bob. You have a rule that you will go out for a pizza only if one, and only one of your friends, pays for it: either Alice or Bob - not both, and not neither of them.\n",
      "\n",
      "This is the principle of Exclusive OR (XOR). In a simple two-input XOR logic:\n",
      "\n",
      "- If Alice pays (True) and Bob doesn't (False), you can go out for pizza. (True)\n",
      "- If Alice doesn't pay (False) and Bob pays (True), you still can go out for pizza. (True)\n",
      "- If neither Alice nor Bob pays (both are False), you can't go out for a pizza. (False) \n",
      "- If both Alice and Bob pay (both are True), it violates your rule, and you won't go out for a pizza. (False)\n",
      "\n",
      "This covers all the possible situations (True/False combinations) for Alice and Bob, demonstrating how the XOR operator works. It's called \"exclusive\" OR because only one input can be true. \n",
      "\n",
      "Would you like me to explain anything else?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi can you please explain exclusive OR to me?\"\n",
    "user.initiate_chat(agent, message=text, clear_history=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start a new chat by clearing the previous chat's history. At this point, common LLM-based assistants would forget everything from the last chat. But `TeachableAgent` can retrieve memories from its vector DB as needed, allowing it to recall and reason over facts that the user taught it in earlier conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-278",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
