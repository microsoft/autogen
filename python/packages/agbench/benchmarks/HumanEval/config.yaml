# config.yaml
#
# The contents of this file will be copied into the 'config.yaml' file of
# every expanded Task, just prior to running the scenario. This provides a
# good place to store model or other configurations important for the scenario.

###############################
# Open AI model configuration #
###############################
# model_config:
#   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
#   config:
#     model: gpt-4o


##############################
# Ollama model configuration #
##############################
model_config:
   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
   config:
     model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
     base_url: http://localhost:8000/v1/
     api_key: "apikey"
     model_info:
       function_calling: false
       json_output: false
       vision: false
       family: "r1"
