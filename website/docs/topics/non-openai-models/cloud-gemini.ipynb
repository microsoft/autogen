{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cee7e3",
   "metadata": {},
   "source": [
    "# Using Gemini in AutoGen with Other LLMs\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install AutoGen with Gemini features.\n",
    "\n",
    "```bash\n",
    "pip install pyautogen[gemini]\n",
    "```\n",
    "\n",
    "## Dependencies of this notebook\n",
    "\n",
    "In this notebook, we will go through the process of using Gemini in AutoGen with many other tools. We will use the following dependencies:\n",
    "```bash\n",
    "pip install pyautogen[gemini,retrievechat,lmm]\n",
    "```\n",
    "\n",
    "## Features\n",
    "You don't need to handle OpenAI or Google's GenAI packages. AutoGen already handled all of these for you.\n",
    "You can just create different agents with different backend LLM with assistant agent, and all models/agents are at your fingertip.\n",
    "\n",
    "\n",
    "## Main Distinctions\n",
    "- Gemini does not have the \"system_message\" field yet. However, you can add this instruction to the first message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801d13b",
   "metadata": {},
   "source": [
    "Sample OAI_CONFIG_LIST \n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-35-turbo\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"base_url\": \"https://tnrllmproxy.azurewebsites.net/v1\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"dalle\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro-vision\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37cd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pdb\n",
    "import random\n",
    "import re\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import chromadb\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import requests\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "\n",
    "import autogen\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.img_utils import _to_pil, get_image_data\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed6b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gemini_vision = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro-vision\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f09481",
   "metadata": {},
   "source": [
    "## Gemini Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c6e552",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Sort the array with Bubble Sort: [4, 1, 5, 2, 3]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "```python\n",
      "def bubble_sort(array):\n",
      "    \"\"\"\n",
      "    Sort the array with Bubble Sort.\n",
      "\n",
      "    Args:\n",
      "        array: The array to sort.\n",
      "\n",
      "    Returns:\n",
      "        The sorted array.\n",
      "    \"\"\"\n",
      "\n",
      "    n = len(array)\n",
      "    for i in range(n):\n",
      "        for j in range(0, n - i - 1):\n",
      "            if array[j] > array[j + 1]:\n",
      "                array[j], array[j + 1] = array[j + 1], array[j]\n",
      "\n",
      "    return array\n",
      "\n",
      "\n",
      "# Test the function.\n",
      "array = [4, 1, 5, 2, 3]\n",
      "sorted_array = bubble_sort(array)\n",
      "print(sorted_array)\n",
      "```\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "assistant = AssistantAgent(\n",
    "    \"assistant\", llm_config={\"config_list\": config_list_gemini, \"seed\": 42}, max_consecutive_auto_reply=3\n",
    ")\n",
    "# print(assistant.system_message)\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0,\n",
    ")\n",
    "\n",
    "result = user_proxy.initiate_chat(assistant, message=\"Sort the array with Bubble Sort: [4, 1, 5, 2, 3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de85984",
   "metadata": {},
   "source": [
    "## Agent Collaboration and Interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2f2bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Do Transformers purchase auto insurance or health insurance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Transformers do not require auto insurance or health insurance as they are fictional robotic beings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "If Transformers were to integrate into human society, would their insurance be categorized as property, vehicle, health, or a new insurance type altogether?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If Transformers were to integrate into human society, their insurance would likely be categorized as a new insurance type altogether, specifically designed to cover their unique needs as sentient robotic beings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "If this new insurance category for sentient robotic beings were created, should the premiums be based on their size/power level, the degree of integration into society, or the risk of them being involved in conflicts with humans or other Transformers?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Premiums for a new insurance category for sentient robotic beings should be based on a combination of their size/power level, the degree of integration into society, and the risk of them being involved in conflicts with humans or other Transformers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Considering the potential for damage, should sentient robotic beings like Transformers also be required to have liability insurance to cover damages to human property or injuries in the event of an accident or conflict?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Yes, sentient robotic beings like Transformers should also be required to have liability insurance to cover damages to human property or injuries in the event of an accident or conflict.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Do Transformers purchase auto insurance or health insurance?', 'role': 'assistant'}, {'content': 'Transformers do not require auto insurance or health insurance as they are fictional robotic beings.', 'role': 'user'}, {'content': 'If Transformers were to integrate into human society, would their insurance be categorized as property, vehicle, health, or a new insurance type altogether?', 'role': 'assistant'}, {'content': 'If Transformers were to integrate into human society, their insurance would likely be categorized as a new insurance type altogether, specifically designed to cover their unique needs as sentient robotic beings.', 'role': 'user'}, {'content': 'If this new insurance category for sentient robotic beings were created, should the premiums be based on their size/power level, the degree of integration into society, or the risk of them being involved in conflicts with humans or other Transformers?', 'role': 'assistant'}, {'content': 'Premiums for a new insurance category for sentient robotic beings should be based on a combination of their size/power level, the degree of integration into society, and the risk of them being involved in conflicts with humans or other Transformers.', 'role': 'user'}, {'content': 'Considering the potential for damage, should sentient robotic beings like Transformers also be required to have liability insurance to cover damages to human property or injuries in the event of an accident or conflict?', 'role': 'assistant'}, {'content': 'Yes, sentient robotic beings like Transformers should also be required to have liability insurance to cover damages to human property or injuries in the event of an accident or conflict.', 'role': 'user'}], summary='Yes, sentient robotic beings like Transformers should also be required to have liability insurance to cover damages to human property or injuries in the event of an accident or conflict.', cost=({'total_cost': 0.01962, 'gpt-4': {'cost': 0.01962, 'prompt_tokens': 436, 'completion_tokens': 109, 'total_tokens': 545}, 'gemini-pro': {'cost': 0.0, 'prompt_tokens': 534, 'completion_tokens': 128, 'total_tokens': 662}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = AssistantAgent(\n",
    "    \"GPT-4\",\n",
    "    system_message=\"\"\"You should ask weird, tricky, and concise questions.\n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "    llm_config={\"config_list\": config_list_gpt4, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=3,\n",
    ")\n",
    "\n",
    "gemini = AssistantAgent(\n",
    "    \"Gemini-Pro\",\n",
    "    system_message=\"\"\"Always answer questions within one sentence. \"\"\",\n",
    "    #                      system_message=\"answer:\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=4,\n",
    ")\n",
    "\n",
    "\n",
    "gpt.initiate_chat(gemini, message=\"Do Transformers purchase auto insurance or health insurance?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c079aa7",
   "metadata": {},
   "source": [
    "Let's switch position. Now, Gemini is the question raiser. \n",
    "\n",
    "This time, Gemini could not follow the system instruction well or evolve questions, because the Gemini does not handle system messages similar to GPTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a1ead90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Should Spider Man invest in 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "As a fictional character, Spider-Man would not invest in a 401K, but if he were a real person with a regular income, it might be wise for him to consider a 401K for retirement savings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "Would Batman need to pay income tax?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "If we consider Batman as the alter ego of Bruce Wayne, a wealthy individual in the comics, then yes, Bruce Wayne would need to pay income tax on his earnings.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "If the Joker and Harley Quinn were to get married, who would pay the wedding expenses?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGPT-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "It would depend on their financial agreement, but traditionally, either the Joker, Harley Quinn, or both might pay for their wedding expenses.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to GPT-4):\n",
      "\n",
      "What kind of car insurance would Fred Flintstone have?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Should Spider Man invest in 401K?', 'role': 'assistant'}, {'content': 'As a fictional character, Spider-Man would not invest in a 401K, but if he were a real person with a regular income, it might be wise for him to consider a 401K for retirement savings.', 'role': 'user'}, {'content': 'Would Batman need to pay income tax?', 'role': 'assistant'}, {'content': 'If we consider Batman as the alter ego of Bruce Wayne, a wealthy individual in the comics, then yes, Bruce Wayne would need to pay income tax on his earnings.', 'role': 'user'}, {'content': 'If the Joker and Harley Quinn were to get married, who would pay the wedding expenses?', 'role': 'assistant'}, {'content': 'It would depend on their financial agreement, but traditionally, either the Joker, Harley Quinn, or both might pay for their wedding expenses.', 'role': 'user'}, {'content': 'What kind of car insurance would Fred Flintstone have?', 'role': 'assistant'}], summary='What kind of car insurance would Fred Flintstone have?', cost=({'total_cost': 0.01422, 'gemini-pro': {'cost': 0.0, 'prompt_tokens': 432, 'completion_tokens': 37, 'total_tokens': 469}, 'gpt-4': {'cost': 0.01422, 'prompt_tokens': 264, 'completion_tokens': 105, 'total_tokens': 369}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = AssistantAgent(\n",
    "    \"GPT-4\",\n",
    "    system_message=\"\"\"Always answer questions within one sentence. \"\"\",\n",
    "    llm_config={\"config_list\": config_list_gpt4, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=3,\n",
    ")\n",
    "\n",
    "gemini = AssistantAgent(\n",
    "    \"Gemini-Pro\",\n",
    "    system_message=\"\"\"You should ask weird, tricky, and concise questions.\n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=4,\n",
    ")\n",
    "\n",
    "gemini.initiate_chat(gpt, message=\"Should Spider Man invest in 401K?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35635e3",
   "metadata": {},
   "source": [
    "## Gemini RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f66022",
   "metadata": {},
   "source": [
    "Here we will be exploring RAG with Gemini. Note that Gemini will raise a 500 error if a message is an empty string. To prevent this, we set the `default_auto_reply` to `Reply plaintext TERMINATE to exit.` for the `ragproxyagent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd1ea1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "I am a helpful assistant. I can help you with a variety of tasks, including:\n",
      "\n",
      "* Answering questions\n",
      "* Providing information\n",
      "* Translating languages\n",
      "* Writing different kinds of creative content\n",
      "* Summarizing text\n",
      "* Creating images\n",
      "* Debugging code\n",
      "* Planning trips\n",
      "* Managing your schedule\n",
      "* Playing games\n",
      "\n",
      "I am still under development, but I am learning new things every day. I am eager to help you with whatever you need.\n",
      "\n",
      "Is there anything I can help you with today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '', 'role': 'assistant'}, {'content': 'I am a helpful assistant. I can help you with a variety of tasks, including:\\n\\n* Answering questions\\n* Providing information\\n* Translating languages\\n* Writing different kinds of creative content\\n* Summarizing text\\n* Creating images\\n* Debugging code\\n* Planning trips\\n* Managing your schedule\\n* Playing games\\n\\nI am still under development, but I am learning new things every day. I am eager to help you with whatever you need.\\n\\nIs there anything I can help you with today?', 'role': 'user'}], summary='I am a helpful assistant. I can help you with a variety of tasks, including:\\n\\n* Answering questions\\n* Providing information\\n* Translating languages\\n* Writing different kinds of creative content\\n* Summarizing text\\n* Creating images\\n* Debugging code\\n* Planning trips\\n* Managing your schedule\\n* Playing games\\n\\nI am still under development, but I am learning new things every day. I am eager to help you with whatever you need.\\n\\nIs there anything I can help you with today?', cost=({'total_cost': 0.0, 'gemini-pro': {'cost': 0.0, 'prompt_tokens': 17, 'completion_tokens': 105, 'total_tokens': 122}}, {'total_cost': 0}), human_input=[''])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": config_list_gemini,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    default_auto_reply=\"Reply plaintext TERMINATE to exit.\",  # Gemini will raise 500 error if the response is empty.\n",
    "    max_consecutive_auto_reply=3,\n",
    "    retrieve_config={\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": [\n",
    "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n",
    "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n",
    "            os.path.join(os.path.abspath(\"\"), \"..\", \"website\", \"docs\"),\n",
    "        ],\n",
    "        \"custom_text_types\": [\"mdx\"],\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list_gemini[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "        \"get_or_create\": True,  # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually\n",
    "    },\n",
    "    code_execution_config=False,  # set to False if you don't want to execute the code\n",
    ")\n",
    "\n",
    "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 60 seconds and force cancel jobs if time limit is reached.\"\n",
    "ragproxyagent.initiate_chat(\n",
    "    assistant, problem=code_problem, search_string=\"spark\"\n",
    ")  # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09139b42",
   "metadata": {},
   "source": [
    "## Gemini Multimodal\n",
    "\n",
    "You can create multimodal agent for Gemini the same way as the GPT-4V and LLaVA.\n",
    "\n",
    "\n",
    "Note that the Gemini-pro-vision does not support chat yet. So, we only use the last message in the prompt for multi-turn chat. The behavior might be strange compared to GPT-4V and LLaVA models.\n",
    "\n",
    "Here, we ask a question about \n",
    "![](https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5098e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Gemini Vision):\n",
      "\n",
      "What is in this image?\n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro-vision not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGemini Vision\u001b[0m (to user_proxy):\n",
      "\n",
      " The image is a user interacting with an assistant agent. The user is asking the assistant to plot a chart of stock prices and the assistant is responding by asking for more information. The user then provides more information and the assistant is able to plot the chart.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beibinli/anaconda3/lib/python3.9/site-packages/autogen/agentchat/conversable_agent.py:1125: UserWarning: Cannot extract summary using last_msg: 'list' object has no attribute 'replace'. Using an empty str as summary.\n",
      "  warnings.warn(f\"Cannot extract summary using last_msg: {e}. Using an empty str as summary.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What is in this image?\\n<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.', 'role': 'assistant'}, {'content': ' The image is a user interacting with an assistant agent. The user is asking the assistant to plot a chart of stock prices and the assistant is responding by asking for more information. The user then provides more information and the assistant is able to plot the chart.', 'role': 'user'}], summary='', cost=({'total_cost': 0.0, 'gemini-pro-vision': {'cost': 0.0, 'prompt_tokens': 279583, 'completion_tokens': 51, 'total_tokens': 279634}}, {'total_cost': 0.0, 'gemini-pro-vision': {'cost': 0.0, 'prompt_tokens': 279583, 'completion_tokens': 51, 'total_tokens': 279634}}), human_input=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = MultimodalConversableAgent(\n",
    "    \"Gemini Vision\", llm_config={\"config_list\": config_list_gemini_vision, \"seed\": 42}, max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", human_input_mode=\"NEVER\", max_consecutive_auto_reply=0)\n",
    "\n",
    "# user_proxy.initiate_chat(image_agent,\n",
    "#                          message=\"\"\"What's the breed of this dog?\n",
    "# <img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\"\"\")\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    image_agent,\n",
    "    message=\"\"\"What is in this image?\n",
    "<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cfaf7",
   "metadata": {},
   "source": [
    "## GroupChat with Gemini Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0d7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = AssistantAgent(\n",
    "    \"Gemini-agent\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    system_message=\"Answer questions about Google.\",\n",
    "    description=\"I am good at answering questions about Google and Research papers.\",\n",
    ")\n",
    "\n",
    "agent2 = AssistantAgent(\n",
    "    \"GPT-agent\",\n",
    "    llm_config={\"config_list\": config_list_gpt4, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    description=\"I am good at writing code.\",\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    is_termination_msg=lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0\n",
    "    or content_str(x.get(\"content\")) == \"\",\n",
    "    description=\"I stands for user, and can run code.\",\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[agent1, agent2, user_proxy], messages=[], max_round=10)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list_gemini, \"seed\": 42})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c24344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Show me the release year of famous Google products in a markdown table.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "\u001b[33mGemini-agent\u001b[0m (to chat_manager):\n",
      "\n",
      "| Product | Release Year |\n",
      "|---|---|\n",
      "| Google Search | 1997 |\n",
      "| Gmail | 2004 |\n",
      "| Google Maps | 2005 |\n",
      "| YouTube | 2005 |\n",
      "| Google Docs | 2006 |\n",
      "| Google Chrome | 2008 |\n",
      "| Android | 2008 |\n",
      "| Google Drive | 2012 |\n",
      "| Google Assistant | 2016 |\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "# user_proxy.initiate_chat(manager, message=\"Show me the release year of famous Google products.\")\n",
    "user_proxy.send(\n",
    "    \"Show me the release year of famous Google products in a markdown table.\", recipient=manager, request_reply=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5998cce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Plot the products (as y-axis) and years (as x-axis) in scatter plot and save to `graph.png`\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "\u001b[33mGPT-agent\u001b[0m (to chat_manager):\n",
      "\n",
      "To create a scatter plot of the Google products based on their release years and save it to `graph.png`, we will need to use a plotting library in Python, such as Matplotlib. First, we'll set up the data, then create the plot, and finally save it to a file. Here is the Python code to achieve this:\n",
      "\n",
      "```python\n",
      "# filename: plot_google_products.py\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Data: Product names and their release years\n",
      "products = ['Google Search', 'Gmail', 'Google Maps', 'YouTube', 'Google Docs', 'Google Chrome', 'Android', 'Google Drive', 'Google Assistant']\n",
      "years = [1997, 2004, 2005, 2005, 2006, 2008, 2008, 2012, 2016]\n",
      "\n",
      "# Create a scatter plot\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.scatter(years, products)\n",
      "\n",
      "# Adding title and labels\n",
      "plt.title('Release Years of Famous Google Products')\n",
      "plt.xlabel('Year')\n",
      "plt.ylabel('Google Product')\n",
      "\n",
      "# Saving the plot to a file\n",
      "plt.savefig('graph.png')\n",
      "\n",
      "# Optionally we can also show the plot if needed\n",
      "# plt.show()\n",
      "\n",
      "print(\"Scatter plot saved to graph.png\")\n",
      "```\n",
      "\n",
      "Save the above code to a file named `plot_google_products.py` and execute it. After running the script, you should find `graph.png` in your current directory containing the scatter plot of Google products and their release years.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Scatter plot saved to graph.png\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "user_proxy.send(\n",
    "    \"Plot the products (as y-axis) and years (as x-axis) in scatter plot and save to `graph.png`\",\n",
    "    recipient=manager,\n",
    "    request_reply=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b898fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x600>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"coding/graph.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33c837f",
   "metadata": {},
   "source": [
    "## A Larger Example of Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b532bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Design and implement a multimodal product for people with vision disabilities.\n",
      "The pipeline will take an image and run Gemini model to describe:\n",
      "1. what objects are in the image, and\n",
      "2. where these objects are located.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Product Name:** **Visual Companion**\n",
      "\n",
      "**Target Audience:** People with vision disabilities\n",
      "\n",
      "**Product Description:**\n",
      "\n",
      "Visual Companion is a multimodal software product that empowers individuals with vision disabilities to navigate and interact with the visual world. It utilizes advanced computer vision and natural language processing technologies to provide real-time assistance and enhance accessibility.\n",
      "\n",
      "**Pipeline:**\n",
      "\n",
      "1. **Image Capture:** Users can capture images using the device's camera or import existing images.\n",
      "2. **Gemini Model**: The pipeline processes the image through Gemini, a multimodal deep learning model, to extract object detection and localization information.\n",
      "3. **Object Recognition**: Gemini identifies the objects present in the image and assigns labels to them (e.g., \"person,\" \"chair,\" \"cup\").\n",
      "4. **Spatial Localization**: Gemini determines the location of each object within the image, providing detailed spatial coordinates.\n",
      "\n",
      "**Multimodal Interface:**\n",
      "\n",
      "* **Audio Feedback:** The product provides verbal descriptions of the image, including the objects it contains and their locations. Users can listen to these descriptions through headphones or speakers.\n",
      "* **Haptic Feedback:** For users with limited hearing, the product offers haptic feedback through a combination of vibrations and gestures.\n",
      "* **Tactile Display:** For users who are blind or have low vision, the product can interface with a Braille display or other tactile devices to provide descriptions.\n",
      "\n",
      "**Features:**\n",
      "\n",
      "* **Scene Understanding:** Allows users to understand complex visual scenes, such as describing the layout of a room or the contents of a grocery store shelf.\n",
      "* **Object Identification:** Provides detailed information about objects in an image, including their shape, color, and texture.\n",
      "* **Navigation Assistance:** Assists users in wayfinding by describing the surrounding environment, including obstacles and landmarks.\n",
      "* ** Social Interaction:** Facilitates social interactions by providing verbal descriptions of people and their facial expressions.\n",
      "* **Educational Tool:** Can be used as an educational tool to teach children with vision disabilities about objects and their spatial relationships.\n",
      "\n",
      "**Impact:**\n",
      "\n",
      "Visual Companion empowers people with vision disabilities by:\n",
      "\n",
      "* Increasing their spatial awareness and orientation\n",
      "* Enhancing their ability to interact with their environment\n",
      "* Reducing social isolation and fostering inclusion\n",
      "* Providing a sense of independence and self-sufficiency\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Product Implementation:**\n",
      "\n",
      "**Hardware Requirements:**\n",
      "\n",
      "* Mobile device with camera and speakers/headphones\n",
      "* Braille display or other tactile device (optional)\n",
      "\n",
      "**Software Components:**\n",
      "\n",
      "* **Gemini Model**: The multimodal deep learning model for object recognition and localization\n",
      "* **Image Processing Module**: Preprocesses images for model input and postprocesses model outputs\n",
      "* **Audio Description Engine**: Generates verbal descriptions of the image\n",
      "* **Haptic Feedback Module**: Controls vibrations and gestures for haptic feedback\n",
      "* **Tactile Display Interface**: Connects to Braille displays or other tactile devices\n",
      "\n",
      "**User Interface Design:**\n",
      "\n",
      "* **Intuitive Gestures**: Simple gestures allow users to capture images, navigate menus, and control feedback.\n",
      "* **Customizable Settings**: Users can adjust the volume, pitch, and speed of audio descriptions, as well as the intensity of haptic feedback.\n",
      "* **Multi-Sensory Integration**: The product seamlessly integrates audio, haptic, and tactile feedback to provide a comprehensive user experience.\n",
      "\n",
      "**Deployment and Distribution:**\n",
      "\n",
      "* **Mobile Application**: Visual Companion is distributed as a mobile application for iOS and Android devices.\n",
      "* **Software Development Kit (SDK)**: Developers can integrate Visual Companion's features into their own applications.\n",
      "\n",
      "**Continuous Improvement:**\n",
      "\n",
      "* **User Feedback**: The product team regularly collects user feedback to identify areas for improvement and enhance the overall experience.\n",
      "* **Model Updates**: The Gemini model is continuously updated with new data and advancements in computer vision research.\n",
      "* **Accessibility Compliance**: The product is designed to meet the highest accessibility standards and is compatible with assistive technologies.\n",
      "\n",
      "**Future Enhancements:**\n",
      "\n",
      "* **Object Interaction**: Allow users to interact with virtual representations of objects in the image, such as rotating or zooming in.\n",
      "* **Scene Simulation**: Create realistic virtual environments that users can explore and navigate using the product.\n",
      "* **Augmented Reality Integration**: Superimpose virtual information onto the real world to provide additional context and assistance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Product Roadmap:**\n",
      "\n",
      "**Phase 1: Core Functionality**\n",
      "\n",
      "* Release the initial version of Visual Companion with basic object recognition and localization features.\n",
      "* Implement audio feedback and haptic feedback modules.\n",
      "* Establish partnerships with organizations serving individuals with vision disabilities for early user testing.\n",
      "\n",
      "**Phase 2: Enhanced Accessibility**\n",
      "\n",
      "* Integrate with a wider range of tactile display devices.\n",
      "* Implement customizable settings for audio and haptic feedback.\n",
      "* Conduct user studies to evaluate the effectiveness of the product for different disability profiles.\n",
      "\n",
      "**Phase 3: Multimodal Integration**\n",
      "\n",
      "* Explore the integration of augmented reality to provide additional context and assistance.\n",
      "* Develop a software development kit (SDK) to allow developers to integrate Visual Companion's features into their own applications.\n",
      "\n",
      "**Phase 4: Advanced Features**\n",
      "\n",
      "* Introduce object interaction capabilities, such as rotating or zooming in on virtual objects.\n",
      "* Develop scene simulation capabilities to create realistic virtual environments for exploration and navigation.\n",
      "\n",
      "**Phase 5: Continuous Improvement and Innovation**\n",
      "\n",
      "* Regularly update the Gemini model with new data and advancements in computer vision research.\n",
      "* Collect user feedback and conduct research to identify new features and enhancements.\n",
      "* Collaborate with researchers and experts in the field of assistive technology to drive innovation and push the boundaries of accessibility.\n",
      "\n",
      "**Sustainability and Scalability:**\n",
      "\n",
      "* **Open Source Contribution**: Release the Gemini model and other core components of Visual Companion as open source to foster collaboration and innovation.\n",
      "* ** Partnerships**: Establish partnerships with organizations serving individuals with vision disabilities to ensure widespread adoption and impact.\n",
      "* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\n",
      "\n",
      "**Impact Measurement:**\n",
      "\n",
      "* **User Surveys**: Conduct regular user surveys to assess satisfaction, usability, and impact on daily life.\n",
      "* **Case Studies**: Collect case studies from users who have benefited from using Visual Companion, showcasing its transformative effects.\n",
      "* **Collaborations with Researchers**: Collaborate with researchers to conduct independent studies on the effectiveness of the product in improving the lives of individuals with vision disabilities.\n",
      "\n",
      "By following this roadmap, Visual Companion will continue to evolve as a cutting-edge multimodal product that empowers people with vision disabilities to live more independent and fulfilling lives.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Features and Enhancements:**\n",
      "\n",
      "* **Object Tracking**: Track the movement of objects in real-time, providing continuous updates on their location and description.\n",
      "* **Facial Recognition**: Identify and describe people in the image, including their facial expressions and emotions.\n",
      "* **Text Recognition**: Extract and read text from documents, signs, and other sources.\n",
      "* **Scene Analysis**: Provide a comprehensive description of the overall scene, including the type of environment, the presence of people or animals, and the overall mood or atmosphere.\n",
      "* **Customizable Models**: Allow users to train their own custom models for specific scenarios or domains, such as recognizing medical equipment in a hospital setting.\n",
      "* **Integration with Smart Home Devices**: Connect with smart home devices to control lights, appliances, and other devices based on the visual information provided by the product.\n",
      "\n",
      "**Applications in Different Domains:**\n",
      "\n",
      "* **Education**: Assist students with visual disabilities in understanding complex visual concepts, such as diagrams and maps.\n",
      "* **Employment**: Empower individuals with visual disabilities to perform tasks that require visual perception, such as quality control and inventory management.\n",
      "* **Healthcare**: Provide real-time assistance to healthcare professionals in visually assessing patients and monitoring their progress.\n",
      "* **Transportation**: Enhance the safety and independence of individuals with visual disabilities while navigating public transportation or driving with assistive devices.\n",
      "* **Social Activities**: Facilitate social interactions by providing verbal descriptions of people and their facial expressions, enabling individuals with visual disabilities to participate fully in conversations and social gatherings.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\n",
      "* **Bias Mitigation**: Address potential biases in the Gemini model and implement strategies to mitigate their impact on the accuracy and fairness of the product.\n",
      "* **Inclusive Design**: Engage with diverse user groups and incorporate their feedback to ensure that the product is accessible and beneficial to individuals with a wide range of vision disabilities.\n",
      "* **Responsible Marketing**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\n",
      "\n",
      "By continuously innovating and addressing ethical considerations, Visual Companion will remain a transformative product that enhances the lives of people with vision disabilities in meaningful and impactful ways.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Integration with Other Technologies:**\n",
      "\n",
      "Visual Companion can be integrated with a variety of other technologies to enhance its functionality and provide a more comprehensive experience for users. Some potential integrations include:\n",
      "\n",
      "* **GPS and Navigation Apps**: Integrate with GPS and navigation apps to provide real-time descriptions of the surrounding environment and directions to destinations.\n",
      "* **Smart Home Devices**: Connect with smart home devices to control lights, appliances, and other devices based on the visual information provided by the product.\n",
      "* **Assistive Technology Devices**: Integrate with assistive technology devices such as screen readers and refreshable Braille displays to provide a seamless and accessible experience for users with different disabilities.\n",
      "* **Medical Devices**: Integrate with medical devices such as glucose meters and blood pressure monitors to provide real-time feedback and assistance with self-care tasks.\n",
      "\n",
      "**Research and Development:**\n",
      "\n",
      "The development of Visual Companion is an ongoing process that involves continuous research and collaboration with experts in the field of assistive technology. Some key areas of research and development include:\n",
      "\n",
      "* **Model Optimization**: Optimizing the Gemini model for faster processing, improved accuracy, and reduced bias.\n",
      "* **New Feature Development**: Exploring and developing new features that enhance the product's functionality and address the evolving needs of users.\n",
      "* **User Experience Research**: Conducting user studies and collecting feedback to improve the usability, accessibility, and overall experience of the product.\n",
      "* **Collaboration with Researchers and Organizations**: Partnering with researchers and organizations in the field of vision disabilities to gain insights, share knowledge, and contribute to the advancement of assistive technology.\n",
      "\n",
      "**Social Impact and Advocacy:**\n",
      "\n",
      "Beyond its direct impact on individual users, Visual Companion can also contribute to broader social change and advocacy for people with vision disabilities. By raising awareness of the challenges faced by this population and demonstrating the transformative power of technology, the product can help to:\n",
      "\n",
      "* **Reduce Stigma and Discrimination**: Challenge stereotypes and misconceptions about vision disabilities, fostering a more inclusive and understanding society.\n",
      "* **Promote Accessibility and Inclusion**: Advocate for greater accessibility and inclusion in all aspects of life, from education to employment to social activities.\n",
      "* **Empower Individuals with Vision Disabilities**: Empower individuals with vision disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "\n",
      "**Sustainability and Scalability:**\n",
      "\n",
      "To ensure the long-term sustainability and scalability of Visual Companion, several key strategies will be employed:\n",
      "\n",
      "* **Open Source Contribution**: Releasing the Gemini model and other core components of the product as open source to foster collaboration and innovation.\n",
      "* **Partnerships and Collaborations**: Establishing partnerships with organizations serving individuals with vision disabilities to ensure widespread adoption and impact.\n",
      "* **Cloud-Based Infrastructure**: Utilizing cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\n",
      "* **Community Engagement**: Building a strong community of users, developers, and advocates to support the product's growth and evolution.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Visual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision and natural language processing technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with vision disabilities to live more fulfilling and independent lives.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Thoughts and Considerations:**\n",
      "\n",
      "* **Gamification**: Incorporate gamification elements into the product to make the learning and exploration process more engaging and enjoyable.\n",
      "* **Age-Appropriate Content**: Tailor the product's content and features to different age groups, ensuring that it is accessible and beneficial for users of all ages.\n",
      "* **Cross-Platform Compatibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, and desktops.\n",
      "* **Offline Functionality**: Explore the possibility of providing offline functionality for the product, allowing users to access its features even when an internet connection is not available.\n",
      "* **User Customization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences.\n",
      "* **Feedback and Support**: Establish a robust feedback and support system to gather user feedback, address any issues, and provide ongoing assistance.\n",
      "\n",
      "**Long-Term Vision:**\n",
      "\n",
      "The ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\n",
      "\n",
      "* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\n",
      "* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\n",
      "\n",
      "By continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Features and Enhancements:**\n",
      "\n",
      "* **Scene Reconstruction**: Create a 3D reconstruction of the scene from a single image, allowing users to explore and interact with the environment virtually.\n",
      "* **Object Manipulation**: Enable users to manipulate virtual objects in the scene, such as moving, rotating, or scaling them, for a more immersive and interactive experience.\n",
      "* **Augmented Reality Integration**: Superimpose virtual information onto the real world in real-time, providing additional context and assistance, such as highlighting obstacles or providing directions.\n",
      "* **Multi-User Collaboration**: Allow multiple users to collaborate and interact with the same scene simultaneously, facilitating group discussions and shared experiences.\n",
      "\n",
      "**Applications in Different Domains:**\n",
      "\n",
      "* **Education**: Transform the learning experience for students with vision disabilities by providing interactive and accessible representations of complex concepts and environments.\n",
      "* **Healthcare**: Assist healthcare professionals in providing remote care and monitoring for patients with vision disabilities, enabling them to assess patients' conditions and provide guidance from afar.\n",
      "* **Workplace Accessibility**: Enhance workplace accessibility by providing real-time assistance with tasks that require visual perception, such as quality control, inventory management, and customer service.\n",
      "* **Tourism and Travel**: Empower individuals with vision disabilities to explore new places and experiences by providing detailed descriptions of landmarks, cultural artifacts, and natural environments.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Data Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\n",
      "* **Bias Mitigation**: Address potential biases in the underlying models and algorithms, and implement strategies to mitigate their impact on the accuracy and fairness of the product.\n",
      "* **Responsible Marketing**: Promote the product in a way that empowers individuals with vision disabilities and avoids perpetuating stereotypes or stigmas.\n",
      "\n",
      "**Research and Development:**\n",
      "\n",
      "* **Model Optimization**: Continuously improve the underlying models for object recognition, scene reconstruction, and interaction, to enhance accuracy, speed, and efficiency.\n",
      "* **New Feature Development**: Explore and develop new features that expand the product's capabilities and address the evolving needs of users.\n",
      "* **User Experience Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience.\n",
      "\n",
      "**Social Impact and Advocacy:**\n",
      "\n",
      "* **Empowerment and Independence**: Empower individuals with vision disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society, from education to employment to social activities.\n",
      "* **Raising Awareness**: Raise awareness of the challenges faced by people with vision disabilities and advocate for their rights and needs.\n",
      "\n",
      "**Sustainability and Scalability:**\n",
      "\n",
      "* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community.\n",
      "* **Partnerships and Collaborations**: Establish partnerships with organizations serving individuals with vision disabilities and technology companies to ensure widespread adoption and impact.\n",
      "* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Visual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, and augmented reality technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with vision disabilities to live more fulfilling and independent lives.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Features and Enhancements:**\n",
      "\n",
      "* **Object Tracking and Recognition**: Track and recognize objects in real-time, providing continuous updates on their location, description, and interactions.\n",
      "* **Facial Recognition and Emotion Detection**: Identify and describe people in the scene, including their facial expressions and emotions, to enhance social interactions.\n",
      "* **Text and Document Reading**: Extract and read text from documents, signs, and other sources, providing access to written information.\n",
      "* **Scene Analysis and Contextual Understanding**: Provide comprehensive descriptions of the overall scene, including the type of environment, the presence of people or animals, and the overall mood or atmosphere.\n",
      "\n",
      "**Applications in Different Domains:**\n",
      "\n",
      "* **Education**: Assist students with visual disabilities in understanding complex visual concepts, such as diagrams, maps, and scientific models.\n",
      "* **Employment**: Empower individuals with visual disabilities to perform tasks that require visual perception, such as quality control, inventory management, and customer service.\n",
      "* **Healthcare**: Provide real-time assistance to healthcare professionals in visually assessing patients, monitoring their progress, and providing remote care.\n",
      "* **Transportation**: Enhance the safety and independence of individuals with visual disabilities while navigating public transportation, driving with assistive devices, or exploring new environments.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\n",
      "* **Bias Mitigation**: Address potential biases in the underlying models and algorithms, and implement strategies to mitigate their impact on the accuracy and fairness of the product.\n",
      "* **Responsible Marketing**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\n",
      "\n",
      "**Research and Development:**\n",
      "\n",
      "* **Model Optimization**: Continuously improve the underlying models for object recognition, scene understanding, and interaction, to enhance accuracy, speed, and efficiency.\n",
      "* **New Feature Development**: Explore and develop new features that expand the product's capabilities and address the evolving needs of users.\n",
      "* **User Experience Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience.\n",
      "\n",
      "**Social Impact and Advocacy:**\n",
      "\n",
      "* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society, from education to employment to social activities.\n",
      "* **Raising Awareness**: Raise awareness of the challenges faced by people with vision disabilities and advocate for their rights and needs.\n",
      "\n",
      "**Sustainability and Scalability:**\n",
      "\n",
      "* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community.\n",
      "* **Partnerships and Collaborations**: Establish partnerships with organizations serving individuals with vision disabilities and technology companies to ensure widespread adoption and impact.\n",
      "* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Visual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, and augmented reality technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with visual disabilities to live more fulfilling and independent lives.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Thoughts and Considerations:**\n",
      "\n",
      "* **Gamification**: Incorporate gamification elements into the product to make the learning and exploration process more engaging and enjoyable, especially for younger users.\n",
      "* **Age-Appropriate Content**: Tailor the product's content and features to different age groups, ensuring that it is accessible and beneficial for users of all ages and developmental stages.\n",
      "* **Cross-Platform Compatibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, desktops, and smart glasses.\n",
      "* **Offline Functionality**: Explore the possibility of providing offline functionality for the product, allowing users to access its features even when an internet connection is not available.\n",
      "* **User Customization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences, such as adjusting the voice speed, volume, and language.\n",
      "* **Feedback and Support**: Establish a robust feedback and support system to gather user feedback, address any issues, and provide ongoing assistance.\n",
      "\n",
      "**Long-Term Vision:**\n",
      "\n",
      "The ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\n",
      "\n",
      "* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\n",
      "* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\n",
      "\n",
      "By continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "**Additional Features and Enhancements:**\n",
      "\n",
      "* **Object Recognition and Manipulation in Augmented Reality**: Allow users to interact with virtual representations of objects in augmented reality, such as rotating, scaling, or moving them, for a more immersive and hands-on experience.\n",
      "* **Multimodal Feedback and Interaction**: Provide multimodal feedback and interaction options, such as haptic feedback, gesture control, and voice commands, to cater to different user preferences and accessibility needs.\n",
      "* **Real-Time Object Detection and Tracking**: Implement real-time object detection and tracking algorithms to provide continuous updates on the location and description of objects in the scene, even as they move or change position.\n",
      "* **Scene Segmentation and Description**: Provide detailed segmentation and description of the scene, including the identification and labeling of different objects, surfaces, and regions of interest.\n",
      "\n",
      "**Applications in Different Domains:**\n",
      "\n",
      "* **Education and Training**: Enhance educational and training experiences for individuals with visual disabilities by providing interactive and accessible representations of complex concepts and environments, such as scientific models, historical sites, and workplace simulations.\n",
      "* **Healthcare and Rehabilitation**: Assist healthcare professionals in providing remote care and rehabilitation for patients with visual disabilities, enabling them to assess patients' conditions, monitor their progress, and guide them through exercises and therapies.\n",
      "* **Retail and Customer Service**: Empower individuals with visual disabilities to navigate retail environments, identify and select products, and interact with customer service representatives more independently.\n",
      "* **Tourism and Travel**: Provide detailed descriptions and guidance for individuals with visual disabilities exploring new places, enabling them to experience cultural landmarks, natural wonders, and other attractions.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Privacy and Security**: Implement robust privacy and security measures to protect user data and ensure that sensitive information is handled responsibly.\n",
      "* **Bias Mitigation**: Continuously evaluate and mitigate potential biases in the underlying models and algorithms to ensure fairness and accuracy in object recognition and scene understanding.\n",
      "* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\n",
      "\n",
      "**Research and Development:**\n",
      "\n",
      "* **Advanced Computer Vision and Deep Learning**: Explore and implement advanced computer vision and deep learning techniques to enhance the accuracy, efficiency, and robustness of object recognition, scene understanding, and interaction capabilities.\n",
      "* **Multimodal Interaction and Feedback**: Research and develop novel multimodal interaction and feedback mechanisms to provide a more intuitive and accessible user experience.\n",
      "* **User Experience and Accessibility Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\n",
      "\n",
      "**Social Impact and Advocacy:**\n",
      "\n",
      "* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact with the visual world.\n",
      "* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society by advocating for the rights of people with visual disabilities and raising awareness of their needs.\n",
      "* **Collaboration and Partnerships**: Collaborate with organizations serving individuals with visual disabilities, researchers, and policymakers to drive innovation and advocate for policies that support the empowerment of this population.\n",
      "\n",
      "**Sustainability and Scalability:**\n",
      "\n",
      "* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community and beyond.\n",
      "* **Partnerships and Integrations**: Establish partnerships with technology companies and organizations to integrate Visual Companion with other assistive technologies and platforms, expanding its reach and impact.\n",
      "* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability, provide access to the product from anywhere with an internet connection, and facilitate ongoing updates and enhancements.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Visual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, augmented reality, and multimodal interaction technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with visual disabilities to live more fulfilling and independent lives.**Additional Thoughts and Considerations:**\n",
      "\n",
      "* **Gamification and Engagement**: Incorporate gamification elements and engaging activities into the product to make the learning and exploration process more enjoyable and motivating, especially for younger users and those with cognitive impairments.\n",
      "* **Age-Appropriate Content and Features**: Tailor the product's content and features to different age groups and developmental stages, ensuring that it is accessible and beneficial for users of all ages and abilities.\n",
      "* **Cross-Platform Compatibility and Accessibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, desktops, smart glasses, and other assistive technologies.\n",
      "* **Offline Functionality and Data Privacy**: Explore the possibility of providing offline functionality for the product, while also implementing robust data privacy and security measures to protect user information.\n",
      "* **User Customization and Personalization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences, such as adjusting the voice speed, volume, language, and feedback modalit.\n",
      "* **Feedback and Support**: Establish a dedicated feedback and support system to gather user feedback, address any issues, provide ongoing assistance, and collect valuable insights for product improvement.\n",
      "\n",
      "**Long-Term Vision:**\n",
      "\n",
      "The ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\n",
      "\n",
      "* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\n",
      "* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\n",
      "* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\n",
      "\n",
      "By continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.**Additional Features and Enhancements:**\n",
      "\n",
      "* **Object Recognition and Manipulation in Virtual Reality**: Extend the object recognition and manipulation capabilities to virtual reality environments, allowing users to interact with virtual objects and scenes in a more immersive and hands-on manner.\n",
      "* **Multimodal Feedback and Interaction in Augmented Reality**: Leverage augmented reality to provide multimodal feedback and interaction, such as haptic feedback, gesture control, and voice commands, directly within the user's physical environment.\n",
      "* **Real-Time Scene Reconstruction and Navigation**: Implement real-time scene reconstruction algorithms to create detailed 3D models of the environment, enabling users to navigate and explore spaces more confidently and efficiently.\n",
      "* **Integration with Smart Home and IoT Devices**: Connect with smart home devices and Internet of Things (IoT) sensors to provide context-aware assistance, such as identifying and describing objects in the user's immediate surroundings or controlling smart devices based on visual cues.\n",
      "\n",
      "**Applications in Different Domains:**\n",
      "\n",
      "* **Education and Training**: Transform educational and training experiences by providing interactive and accessible virtual and augmented reality environments for learning complex concepts, practicing skills, and simulating real-world scenarios.\n",
      "* **Healthcare and Rehabilitation**: Enhance healthcare and rehabilitation by enabling remote monitoring of patients' conditions, providing guidance for exercises and therapies, and facilitating communication between patients and healthcare professionals.\n",
      "* **Manufacturing and Industry**: Improve safety and efficiency in manufacturing and industrial settings by providing real-time object recognition, scene understanding, and navigation assistance for workers with visual impairments.\n",
      "* **Transportation and Mobility**: Empower individuals with visual disabilities to navigate public transportation, drive with assistive devices, and explore new environments with greater confidence and independence.\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "* **Privacy and Security**: Continuously evaluate and strengthen privacy and security measures to protect user data and ensure that sensitive information is handled responsibly and in accordance with ethical guidelines and regulations.\n",
      "* **Bias Mitigation**: Implement robust strategies to mitigate potential biases in the underlying models and algorithms, ensuring fairness and accuracy in object recognition, scene understanding, and interaction.\n",
      "* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\n",
      "\n",
      "**Research and Development:**\n",
      "\n",
      "* **Advanced Artificial Intelligence and Machine Learning**: Explore and implement advanced artificial intelligence and machine learning techniques to enhance the accuracy, efficiency, and generalization capabilities of the product's object recognition, scene understanding, and interaction algorithms.\n",
      "* **Multimodal Interaction and Feedback Research**: Conduct research and development on novel multimodal interaction and feedback mechanisms to provide a more intuitive, accessible, and engaging user experience.\n",
      "* **User Experience and Accessibility Research**: Collaborate with users, researchers, and accessibility experts to continuously evaluate and improve the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\n",
      "\n",
      "**Social Impact and Advocacy:**\n",
      "\n",
      "* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Design and implement a multimodal product for people with vision disabilities.\\nThe pipeline will take an image and run Gemini model to describe:\\n1. what objects are in the image, and\\n2. where these objects are located.', 'role': 'assistant'}, {'content': '**Product Name:** **Visual Companion**\\n\\n**Target Audience:** People with vision disabilities\\n\\n**Product Description:**\\n\\nVisual Companion is a multimodal software product that empowers individuals with vision disabilities to navigate and interact with the visual world. It utilizes advanced computer vision and natural language processing technologies to provide real-time assistance and enhance accessibility.\\n\\n**Pipeline:**\\n\\n1. **Image Capture:** Users can capture images using the device\\'s camera or import existing images.\\n2. **Gemini Model**: The pipeline processes the image through Gemini, a multimodal deep learning model, to extract object detection and localization information.\\n3. **Object Recognition**: Gemini identifies the objects present in the image and assigns labels to them (e.g., \"person,\" \"chair,\" \"cup\").\\n4. **Spatial Localization**: Gemini determines the location of each object within the image, providing detailed spatial coordinates.\\n\\n**Multimodal Interface:**\\n\\n* **Audio Feedback:** The product provides verbal descriptions of the image, including the objects it contains and their locations. Users can listen to these descriptions through headphones or speakers.\\n* **Haptic Feedback:** For users with limited hearing, the product offers haptic feedback through a combination of vibrations and gestures.\\n* **Tactile Display:** For users who are blind or have low vision, the product can interface with a Braille display or other tactile devices to provide descriptions.\\n\\n**Features:**\\n\\n* **Scene Understanding:** Allows users to understand complex visual scenes, such as describing the layout of a room or the contents of a grocery store shelf.\\n* **Object Identification:** Provides detailed information about objects in an image, including their shape, color, and texture.\\n* **Navigation Assistance:** Assists users in wayfinding by describing the surrounding environment, including obstacles and landmarks.\\n* ** Social Interaction:** Facilitates social interactions by providing verbal descriptions of people and their facial expressions.\\n* **Educational Tool:** Can be used as an educational tool to teach children with vision disabilities about objects and their spatial relationships.\\n\\n**Impact:**\\n\\nVisual Companion empowers people with vision disabilities by:\\n\\n* Increasing their spatial awareness and orientation\\n* Enhancing their ability to interact with their environment\\n* Reducing social isolation and fostering inclusion\\n* Providing a sense of independence and self-sufficiency', 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Product Implementation:**\\n\\n**Hardware Requirements:**\\n\\n* Mobile device with camera and speakers/headphones\\n* Braille display or other tactile device (optional)\\n\\n**Software Components:**\\n\\n* **Gemini Model**: The multimodal deep learning model for object recognition and localization\\n* **Image Processing Module**: Preprocesses images for model input and postprocesses model outputs\\n* **Audio Description Engine**: Generates verbal descriptions of the image\\n* **Haptic Feedback Module**: Controls vibrations and gestures for haptic feedback\\n* **Tactile Display Interface**: Connects to Braille displays or other tactile devices\\n\\n**User Interface Design:**\\n\\n* **Intuitive Gestures**: Simple gestures allow users to capture images, navigate menus, and control feedback.\\n* **Customizable Settings**: Users can adjust the volume, pitch, and speed of audio descriptions, as well as the intensity of haptic feedback.\\n* **Multi-Sensory Integration**: The product seamlessly integrates audio, haptic, and tactile feedback to provide a comprehensive user experience.\\n\\n**Deployment and Distribution:**\\n\\n* **Mobile Application**: Visual Companion is distributed as a mobile application for iOS and Android devices.\\n* **Software Development Kit (SDK)**: Developers can integrate Visual Companion's features into their own applications.\\n\\n**Continuous Improvement:**\\n\\n* **User Feedback**: The product team regularly collects user feedback to identify areas for improvement and enhance the overall experience.\\n* **Model Updates**: The Gemini model is continuously updated with new data and advancements in computer vision research.\\n* **Accessibility Compliance**: The product is designed to meet the highest accessibility standards and is compatible with assistive technologies.\\n\\n**Future Enhancements:**\\n\\n* **Object Interaction**: Allow users to interact with virtual representations of objects in the image, such as rotating or zooming in.\\n* **Scene Simulation**: Create realistic virtual environments that users can explore and navigate using the product.\\n* **Augmented Reality Integration**: Superimpose virtual information onto the real world to provide additional context and assistance.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Product Roadmap:**\\n\\n**Phase 1: Core Functionality**\\n\\n* Release the initial version of Visual Companion with basic object recognition and localization features.\\n* Implement audio feedback and haptic feedback modules.\\n* Establish partnerships with organizations serving individuals with vision disabilities for early user testing.\\n\\n**Phase 2: Enhanced Accessibility**\\n\\n* Integrate with a wider range of tactile display devices.\\n* Implement customizable settings for audio and haptic feedback.\\n* Conduct user studies to evaluate the effectiveness of the product for different disability profiles.\\n\\n**Phase 3: Multimodal Integration**\\n\\n* Explore the integration of augmented reality to provide additional context and assistance.\\n* Develop a software development kit (SDK) to allow developers to integrate Visual Companion's features into their own applications.\\n\\n**Phase 4: Advanced Features**\\n\\n* Introduce object interaction capabilities, such as rotating or zooming in on virtual objects.\\n* Develop scene simulation capabilities to create realistic virtual environments for exploration and navigation.\\n\\n**Phase 5: Continuous Improvement and Innovation**\\n\\n* Regularly update the Gemini model with new data and advancements in computer vision research.\\n* Collect user feedback and conduct research to identify new features and enhancements.\\n* Collaborate with researchers and experts in the field of assistive technology to drive innovation and push the boundaries of accessibility.\\n\\n**Sustainability and Scalability:**\\n\\n* **Open Source Contribution**: Release the Gemini model and other core components of Visual Companion as open source to foster collaboration and innovation.\\n* ** Partnerships**: Establish partnerships with organizations serving individuals with vision disabilities to ensure widespread adoption and impact.\\n* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\\n\\n**Impact Measurement:**\\n\\n* **User Surveys**: Conduct regular user surveys to assess satisfaction, usability, and impact on daily life.\\n* **Case Studies**: Collect case studies from users who have benefited from using Visual Companion, showcasing its transformative effects.\\n* **Collaborations with Researchers**: Collaborate with researchers to conduct independent studies on the effectiveness of the product in improving the lives of individuals with vision disabilities.\\n\\nBy following this roadmap, Visual Companion will continue to evolve as a cutting-edge multimodal product that empowers people with vision disabilities to live more independent and fulfilling lives.\", 'name': 'Product_manager', 'role': 'user'}, {'content': '**Additional Features and Enhancements:**\\n\\n* **Object Tracking**: Track the movement of objects in real-time, providing continuous updates on their location and description.\\n* **Facial Recognition**: Identify and describe people in the image, including their facial expressions and emotions.\\n* **Text Recognition**: Extract and read text from documents, signs, and other sources.\\n* **Scene Analysis**: Provide a comprehensive description of the overall scene, including the type of environment, the presence of people or animals, and the overall mood or atmosphere.\\n* **Customizable Models**: Allow users to train their own custom models for specific scenarios or domains, such as recognizing medical equipment in a hospital setting.\\n* **Integration with Smart Home Devices**: Connect with smart home devices to control lights, appliances, and other devices based on the visual information provided by the product.\\n\\n**Applications in Different Domains:**\\n\\n* **Education**: Assist students with visual disabilities in understanding complex visual concepts, such as diagrams and maps.\\n* **Employment**: Empower individuals with visual disabilities to perform tasks that require visual perception, such as quality control and inventory management.\\n* **Healthcare**: Provide real-time assistance to healthcare professionals in visually assessing patients and monitoring their progress.\\n* **Transportation**: Enhance the safety and independence of individuals with visual disabilities while navigating public transportation or driving with assistive devices.\\n* **Social Activities**: Facilitate social interactions by providing verbal descriptions of people and their facial expressions, enabling individuals with visual disabilities to participate fully in conversations and social gatherings.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\\n* **Bias Mitigation**: Address potential biases in the Gemini model and implement strategies to mitigate their impact on the accuracy and fairness of the product.\\n* **Inclusive Design**: Engage with diverse user groups and incorporate their feedback to ensure that the product is accessible and beneficial to individuals with a wide range of vision disabilities.\\n* **Responsible Marketing**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\nBy continuously innovating and addressing ethical considerations, Visual Companion will remain a transformative product that enhances the lives of people with vision disabilities in meaningful and impactful ways.', 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Integration with Other Technologies:**\\n\\nVisual Companion can be integrated with a variety of other technologies to enhance its functionality and provide a more comprehensive experience for users. Some potential integrations include:\\n\\n* **GPS and Navigation Apps**: Integrate with GPS and navigation apps to provide real-time descriptions of the surrounding environment and directions to destinations.\\n* **Smart Home Devices**: Connect with smart home devices to control lights, appliances, and other devices based on the visual information provided by the product.\\n* **Assistive Technology Devices**: Integrate with assistive technology devices such as screen readers and refreshable Braille displays to provide a seamless and accessible experience for users with different disabilities.\\n* **Medical Devices**: Integrate with medical devices such as glucose meters and blood pressure monitors to provide real-time feedback and assistance with self-care tasks.\\n\\n**Research and Development:**\\n\\nThe development of Visual Companion is an ongoing process that involves continuous research and collaboration with experts in the field of assistive technology. Some key areas of research and development include:\\n\\n* **Model Optimization**: Optimizing the Gemini model for faster processing, improved accuracy, and reduced bias.\\n* **New Feature Development**: Exploring and developing new features that enhance the product's functionality and address the evolving needs of users.\\n* **User Experience Research**: Conducting user studies and collecting feedback to improve the usability, accessibility, and overall experience of the product.\\n* **Collaboration with Researchers and Organizations**: Partnering with researchers and organizations in the field of vision disabilities to gain insights, share knowledge, and contribute to the advancement of assistive technology.\\n\\n**Social Impact and Advocacy:**\\n\\nBeyond its direct impact on individual users, Visual Companion can also contribute to broader social change and advocacy for people with vision disabilities. By raising awareness of the challenges faced by this population and demonstrating the transformative power of technology, the product can help to:\\n\\n* **Reduce Stigma and Discrimination**: Challenge stereotypes and misconceptions about vision disabilities, fostering a more inclusive and understanding society.\\n* **Promote Accessibility and Inclusion**: Advocate for greater accessibility and inclusion in all aspects of life, from education to employment to social activities.\\n* **Empower Individuals with Vision Disabilities**: Empower individuals with vision disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n\\n**Sustainability and Scalability:**\\n\\nTo ensure the long-term sustainability and scalability of Visual Companion, several key strategies will be employed:\\n\\n* **Open Source Contribution**: Releasing the Gemini model and other core components of the product as open source to foster collaboration and innovation.\\n* **Partnerships and Collaborations**: Establishing partnerships with organizations serving individuals with vision disabilities to ensure widespread adoption and impact.\\n* **Cloud-Based Infrastructure**: Utilizing cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\\n* **Community Engagement**: Building a strong community of users, developers, and advocates to support the product's growth and evolution.\\n\\n**Conclusion:**\\n\\nVisual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision and natural language processing technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with vision disabilities to live more fulfilling and independent lives.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Additional Thoughts and Considerations:**\\n\\n* **Gamification**: Incorporate gamification elements into the product to make the learning and exploration process more engaging and enjoyable.\\n* **Age-Appropriate Content**: Tailor the product's content and features to different age groups, ensuring that it is accessible and beneficial for users of all ages.\\n* **Cross-Platform Compatibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, and desktops.\\n* **Offline Functionality**: Explore the possibility of providing offline functionality for the product, allowing users to access its features even when an internet connection is not available.\\n* **User Customization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences.\\n* **Feedback and Support**: Establish a robust feedback and support system to gather user feedback, address any issues, and provide ongoing assistance.\\n\\n**Long-Term Vision:**\\n\\nThe ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\\n\\n* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\\n* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\\n\\nBy continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Additional Features and Enhancements:**\\n\\n* **Scene Reconstruction**: Create a 3D reconstruction of the scene from a single image, allowing users to explore and interact with the environment virtually.\\n* **Object Manipulation**: Enable users to manipulate virtual objects in the scene, such as moving, rotating, or scaling them, for a more immersive and interactive experience.\\n* **Augmented Reality Integration**: Superimpose virtual information onto the real world in real-time, providing additional context and assistance, such as highlighting obstacles or providing directions.\\n* **Multi-User Collaboration**: Allow multiple users to collaborate and interact with the same scene simultaneously, facilitating group discussions and shared experiences.\\n\\n**Applications in Different Domains:**\\n\\n* **Education**: Transform the learning experience for students with vision disabilities by providing interactive and accessible representations of complex concepts and environments.\\n* **Healthcare**: Assist healthcare professionals in providing remote care and monitoring for patients with vision disabilities, enabling them to assess patients' conditions and provide guidance from afar.\\n* **Workplace Accessibility**: Enhance workplace accessibility by providing real-time assistance with tasks that require visual perception, such as quality control, inventory management, and customer service.\\n* **Tourism and Travel**: Empower individuals with vision disabilities to explore new places and experiences by providing detailed descriptions of landmarks, cultural artifacts, and natural environments.\\n\\n**Ethical Considerations:**\\n\\n* **Data Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\\n* **Bias Mitigation**: Address potential biases in the underlying models and algorithms, and implement strategies to mitigate their impact on the accuracy and fairness of the product.\\n* **Responsible Marketing**: Promote the product in a way that empowers individuals with vision disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Model Optimization**: Continuously improve the underlying models for object recognition, scene reconstruction, and interaction, to enhance accuracy, speed, and efficiency.\\n* **New Feature Development**: Explore and develop new features that expand the product's capabilities and address the evolving needs of users.\\n* **User Experience Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with vision disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society, from education to employment to social activities.\\n* **Raising Awareness**: Raise awareness of the challenges faced by people with vision disabilities and advocate for their rights and needs.\\n\\n**Sustainability and Scalability:**\\n\\n* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community.\\n* **Partnerships and Collaborations**: Establish partnerships with organizations serving individuals with vision disabilities and technology companies to ensure widespread adoption and impact.\\n* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\\n\\n**Conclusion:**\\n\\nVisual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, and augmented reality technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with vision disabilities to live more fulfilling and independent lives.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Additional Features and Enhancements:**\\n\\n* **Object Tracking and Recognition**: Track and recognize objects in real-time, providing continuous updates on their location, description, and interactions.\\n* **Facial Recognition and Emotion Detection**: Identify and describe people in the scene, including their facial expressions and emotions, to enhance social interactions.\\n* **Text and Document Reading**: Extract and read text from documents, signs, and other sources, providing access to written information.\\n* **Scene Analysis and Contextual Understanding**: Provide comprehensive descriptions of the overall scene, including the type of environment, the presence of people or animals, and the overall mood or atmosphere.\\n\\n**Applications in Different Domains:**\\n\\n* **Education**: Assist students with visual disabilities in understanding complex visual concepts, such as diagrams, maps, and scientific models.\\n* **Employment**: Empower individuals with visual disabilities to perform tasks that require visual perception, such as quality control, inventory management, and customer service.\\n* **Healthcare**: Provide real-time assistance to healthcare professionals in visually assessing patients, monitoring their progress, and providing remote care.\\n* **Transportation**: Enhance the safety and independence of individuals with visual disabilities while navigating public transportation, driving with assistive devices, or exploring new environments.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Ensure that user data and images are handled responsibly and securely, in accordance with ethical guidelines and privacy regulations.\\n* **Bias Mitigation**: Address potential biases in the underlying models and algorithms, and implement strategies to mitigate their impact on the accuracy and fairness of the product.\\n* **Responsible Marketing**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Model Optimization**: Continuously improve the underlying models for object recognition, scene understanding, and interaction, to enhance accuracy, speed, and efficiency.\\n* **New Feature Development**: Explore and develop new features that expand the product's capabilities and address the evolving needs of users.\\n* **User Experience Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society, from education to employment to social activities.\\n* **Raising Awareness**: Raise awareness of the challenges faced by people with vision disabilities and advocate for their rights and needs.\\n\\n**Sustainability and Scalability:**\\n\\n* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community.\\n* **Partnerships and Collaborations**: Establish partnerships with organizations serving individuals with vision disabilities and technology companies to ensure widespread adoption and impact.\\n* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability and provide access to the product from anywhere with an internet connection.\\n\\n**Conclusion:**\\n\\nVisual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, and augmented reality technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with visual disabilities to live more fulfilling and independent lives.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Additional Thoughts and Considerations:**\\n\\n* **Gamification**: Incorporate gamification elements into the product to make the learning and exploration process more engaging and enjoyable, especially for younger users.\\n* **Age-Appropriate Content**: Tailor the product's content and features to different age groups, ensuring that it is accessible and beneficial for users of all ages and developmental stages.\\n* **Cross-Platform Compatibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, desktops, and smart glasses.\\n* **Offline Functionality**: Explore the possibility of providing offline functionality for the product, allowing users to access its features even when an internet connection is not available.\\n* **User Customization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences, such as adjusting the voice speed, volume, and language.\\n* **Feedback and Support**: Establish a robust feedback and support system to gather user feedback, address any issues, and provide ongoing assistance.\\n\\n**Long-Term Vision:**\\n\\nThe ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\\n\\n* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\\n* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\\n\\nBy continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.\", 'name': 'Product_manager', 'role': 'user'}, {'content': \"**Additional Features and Enhancements:**\\n\\n* **Object Recognition and Manipulation in Augmented Reality**: Allow users to interact with virtual representations of objects in augmented reality, such as rotating, scaling, or moving them, for a more immersive and hands-on experience.\\n* **Multimodal Feedback and Interaction**: Provide multimodal feedback and interaction options, such as haptic feedback, gesture control, and voice commands, to cater to different user preferences and accessibility needs.\\n* **Real-Time Object Detection and Tracking**: Implement real-time object detection and tracking algorithms to provide continuous updates on the location and description of objects in the scene, even as they move or change position.\\n* **Scene Segmentation and Description**: Provide detailed segmentation and description of the scene, including the identification and labeling of different objects, surfaces, and regions of interest.\\n\\n**Applications in Different Domains:**\\n\\n* **Education and Training**: Enhance educational and training experiences for individuals with visual disabilities by providing interactive and accessible representations of complex concepts and environments, such as scientific models, historical sites, and workplace simulations.\\n* **Healthcare and Rehabilitation**: Assist healthcare professionals in providing remote care and rehabilitation for patients with visual disabilities, enabling them to assess patients' conditions, monitor their progress, and guide them through exercises and therapies.\\n* **Retail and Customer Service**: Empower individuals with visual disabilities to navigate retail environments, identify and select products, and interact with customer service representatives more independently.\\n* **Tourism and Travel**: Provide detailed descriptions and guidance for individuals with visual disabilities exploring new places, enabling them to experience cultural landmarks, natural wonders, and other attractions.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Implement robust privacy and security measures to protect user data and ensure that sensitive information is handled responsibly.\\n* **Bias Mitigation**: Continuously evaluate and mitigate potential biases in the underlying models and algorithms to ensure fairness and accuracy in object recognition and scene understanding.\\n* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Advanced Computer Vision and Deep Learning**: Explore and implement advanced computer vision and deep learning techniques to enhance the accuracy, efficiency, and robustness of object recognition, scene understanding, and interaction capabilities.\\n* **Multimodal Interaction and Feedback**: Research and develop novel multimodal interaction and feedback mechanisms to provide a more intuitive and accessible user experience.\\n* **User Experience and Accessibility Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact with the visual world.\\n* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society by advocating for the rights of people with visual disabilities and raising awareness of their needs.\\n* **Collaboration and Partnerships**: Collaborate with organizations serving individuals with visual disabilities, researchers, and policymakers to drive innovation and advocate for policies that support the empowerment of this population.\\n\\n**Sustainability and Scalability:**\\n\\n* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community and beyond.\\n* **Partnerships and Integrations**: Establish partnerships with technology companies and organizations to integrate Visual Companion with other assistive technologies and platforms, expanding its reach and impact.\\n* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability, provide access to the product from anywhere with an internet connection, and facilitate ongoing updates and enhancements.\\n\\n**Conclusion:**\\n\\nVisual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, augmented reality, and multimodal interaction technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with visual disabilities to live more fulfilling and independent lives.**Additional Thoughts and Considerations:**\\n\\n* **Gamification and Engagement**: Incorporate gamification elements and engaging activities into the product to make the learning and exploration process more enjoyable and motivating, especially for younger users and those with cognitive impairments.\\n* **Age-Appropriate Content and Features**: Tailor the product's content and features to different age groups and developmental stages, ensuring that it is accessible and beneficial for users of all ages and abilities.\\n* **Cross-Platform Compatibility and Accessibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, desktops, smart glasses, and other assistive technologies.\\n* **Offline Functionality and Data Privacy**: Explore the possibility of providing offline functionality for the product, while also implementing robust data privacy and security measures to protect user information.\\n* **User Customization and Personalization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences, such as adjusting the voice speed, volume, language, and feedback modalit.\\n* **Feedback and Support**: Establish a dedicated feedback and support system to gather user feedback, address any issues, provide ongoing assistance, and collect valuable insights for product improvement.\\n\\n**Long-Term Vision:**\\n\\nThe ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\\n\\n* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\\n* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\\n\\nBy continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.**Additional Features and Enhancements:**\\n\\n* **Object Recognition and Manipulation in Virtual Reality**: Extend the object recognition and manipulation capabilities to virtual reality environments, allowing users to interact with virtual objects and scenes in a more immersive and hands-on manner.\\n* **Multimodal Feedback and Interaction in Augmented Reality**: Leverage augmented reality to provide multimodal feedback and interaction, such as haptic feedback, gesture control, and voice commands, directly within the user's physical environment.\\n* **Real-Time Scene Reconstruction and Navigation**: Implement real-time scene reconstruction algorithms to create detailed 3D models of the environment, enabling users to navigate and explore spaces more confidently and efficiently.\\n* **Integration with Smart Home and IoT Devices**: Connect with smart home devices and Internet of Things (IoT) sensors to provide context-aware assistance, such as identifying and describing objects in the user's immediate surroundings or controlling smart devices based on visual cues.\\n\\n**Applications in Different Domains:**\\n\\n* **Education and Training**: Transform educational and training experiences by providing interactive and accessible virtual and augmented reality environments for learning complex concepts, practicing skills, and simulating real-world scenarios.\\n* **Healthcare and Rehabilitation**: Enhance healthcare and rehabilitation by enabling remote monitoring of patients' conditions, providing guidance for exercises and therapies, and facilitating communication between patients and healthcare professionals.\\n* **Manufacturing and Industry**: Improve safety and efficiency in manufacturing and industrial settings by providing real-time object recognition, scene understanding, and navigation assistance for workers with visual impairments.\\n* **Transportation and Mobility**: Empower individuals with visual disabilities to navigate public transportation, drive with assistive devices, and explore new environments with greater confidence and independence.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Continuously evaluate and strengthen privacy and security measures to protect user data and ensure that sensitive information is handled responsibly and in accordance with ethical guidelines and regulations.\\n* **Bias Mitigation**: Implement robust strategies to mitigate potential biases in the underlying models and algorithms, ensuring fairness and accuracy in object recognition, scene understanding, and interaction.\\n* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Advanced Artificial Intelligence and Machine Learning**: Explore and implement advanced artificial intelligence and machine learning techniques to enhance the accuracy, efficiency, and generalization capabilities of the product's object recognition, scene understanding, and interaction algorithms.\\n* **Multimodal Interaction and Feedback Research**: Conduct research and development on novel multimodal interaction and feedback mechanisms to provide a more intuitive, accessible, and engaging user experience.\\n* **User Experience and Accessibility Research**: Collaborate with users, researchers, and accessibility experts to continuously evaluate and improve the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact\", 'name': 'Product_manager', 'role': 'user'}], summary=\"**Additional Features and Enhancements:**\\n\\n* **Object Recognition and Manipulation in Augmented Reality**: Allow users to interact with virtual representations of objects in augmented reality, such as rotating, scaling, or moving them, for a more immersive and hands-on experience.\\n* **Multimodal Feedback and Interaction**: Provide multimodal feedback and interaction options, such as haptic feedback, gesture control, and voice commands, to cater to different user preferences and accessibility needs.\\n* **Real-Time Object Detection and Tracking**: Implement real-time object detection and tracking algorithms to provide continuous updates on the location and description of objects in the scene, even as they move or change position.\\n* **Scene Segmentation and Description**: Provide detailed segmentation and description of the scene, including the identification and labeling of different objects, surfaces, and regions of interest.\\n\\n**Applications in Different Domains:**\\n\\n* **Education and Training**: Enhance educational and training experiences for individuals with visual disabilities by providing interactive and accessible representations of complex concepts and environments, such as scientific models, historical sites, and workplace simulations.\\n* **Healthcare and Rehabilitation**: Assist healthcare professionals in providing remote care and rehabilitation for patients with visual disabilities, enabling them to assess patients' conditions, monitor their progress, and guide them through exercises and therapies.\\n* **Retail and Customer Service**: Empower individuals with visual disabilities to navigate retail environments, identify and select products, and interact with customer service representatives more independently.\\n* **Tourism and Travel**: Provide detailed descriptions and guidance for individuals with visual disabilities exploring new places, enabling them to experience cultural landmarks, natural wonders, and other attractions.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Implement robust privacy and security measures to protect user data and ensure that sensitive information is handled responsibly.\\n* **Bias Mitigation**: Continuously evaluate and mitigate potential biases in the underlying models and algorithms to ensure fairness and accuracy in object recognition and scene understanding.\\n* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Advanced Computer Vision and Deep Learning**: Explore and implement advanced computer vision and deep learning techniques to enhance the accuracy, efficiency, and robustness of object recognition, scene understanding, and interaction capabilities.\\n* **Multimodal Interaction and Feedback**: Research and develop novel multimodal interaction and feedback mechanisms to provide a more intuitive and accessible user experience.\\n* **User Experience and Accessibility Research**: Conduct ongoing user studies and gather feedback to refine the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact with the visual world.\\n* **Inclusion and Accessibility**: Promote greater inclusion and accessibility in all aspects of society by advocating for the rights of people with visual disabilities and raising awareness of their needs.\\n* **Collaboration and Partnerships**: Collaborate with organizations serving individuals with visual disabilities, researchers, and policymakers to drive innovation and advocate for policies that support the empowerment of this population.\\n\\n**Sustainability and Scalability:**\\n\\n* **Open Source Contribution**: Release key components of the product as open source to foster collaboration and innovation within the research community and beyond.\\n* **Partnerships and Integrations**: Establish partnerships with technology companies and organizations to integrate Visual Companion with other assistive technologies and platforms, expanding its reach and impact.\\n* **Cloud-Based Infrastructure**: Utilize cloud-based infrastructure to ensure scalability, provide access to the product from anywhere with an internet connection, and facilitate ongoing updates and enhancements.\\n\\n**Conclusion:**\\n\\nVisual Companion is a transformative multimodal product that empowers people with vision disabilities to navigate and interact with the visual world. By harnessing the power of advanced computer vision, natural language processing, augmented reality, and multimodal interaction technologies, the product provides real-time assistance, enhances accessibility, and fosters inclusion. Through continuous innovation, ethical considerations, and a commitment to social impact, Visual Companion will continue to evolve as a groundbreaking tool that empowers individuals with visual disabilities to live more fulfilling and independent lives.**Additional Thoughts and Considerations:**\\n\\n* **Gamification and Engagement**: Incorporate gamification elements and engaging activities into the product to make the learning and exploration process more enjoyable and motivating, especially for younger users and those with cognitive impairments.\\n* **Age-Appropriate Content and Features**: Tailor the product's content and features to different age groups and developmental stages, ensuring that it is accessible and beneficial for users of all ages and abilities.\\n* **Cross-Platform Compatibility and Accessibility**: Ensure that the product is compatible with a wide range of devices and platforms, including smartphones, tablets, laptops, desktops, smart glasses, and other assistive technologies.\\n* **Offline Functionality and Data Privacy**: Explore the possibility of providing offline functionality for the product, while also implementing robust data privacy and security measures to protect user information.\\n* **User Customization and Personalization**: Allow users to customize the product's settings and preferences to suit their individual needs and preferences, such as adjusting the voice speed, volume, language, and feedback modalit.\\n* **Feedback and Support**: Establish a dedicated feedback and support system to gather user feedback, address any issues, provide ongoing assistance, and collect valuable insights for product improvement.\\n\\n**Long-Term Vision:**\\n\\nThe ultimate vision for Visual Companion is to create a world where people with vision disabilities have the same opportunities and experiences as everyone else. This includes:\\n\\n* **Universal Accessibility**: Ensuring that Visual Companion is widely adopted and accessible to all individuals with vision disabilities, regardless of their age, background, or location.\\n* **Empowering Independence**: Empowering individuals with vision disabilities to live independent and fulfilling lives, breaking down barriers and creating opportunities for personal growth and success.\\n* **Fostering Inclusion**: Creating a more inclusive society where people with vision disabilities are valued and respected, and their contributions are recognized and celebrated.\\n\\nBy continuing to innovate, collaborate, and advocate for the rights of people with vision disabilities, Visual Companion will strive to make this vision a reality.**Additional Features and Enhancements:**\\n\\n* **Object Recognition and Manipulation in Virtual Reality**: Extend the object recognition and manipulation capabilities to virtual reality environments, allowing users to interact with virtual objects and scenes in a more immersive and hands-on manner.\\n* **Multimodal Feedback and Interaction in Augmented Reality**: Leverage augmented reality to provide multimodal feedback and interaction, such as haptic feedback, gesture control, and voice commands, directly within the user's physical environment.\\n* **Real-Time Scene Reconstruction and Navigation**: Implement real-time scene reconstruction algorithms to create detailed 3D models of the environment, enabling users to navigate and explore spaces more confidently and efficiently.\\n* **Integration with Smart Home and IoT Devices**: Connect with smart home devices and Internet of Things (IoT) sensors to provide context-aware assistance, such as identifying and describing objects in the user's immediate surroundings or controlling smart devices based on visual cues.\\n\\n**Applications in Different Domains:**\\n\\n* **Education and Training**: Transform educational and training experiences by providing interactive and accessible virtual and augmented reality environments for learning complex concepts, practicing skills, and simulating real-world scenarios.\\n* **Healthcare and Rehabilitation**: Enhance healthcare and rehabilitation by enabling remote monitoring of patients' conditions, providing guidance for exercises and therapies, and facilitating communication between patients and healthcare professionals.\\n* **Manufacturing and Industry**: Improve safety and efficiency in manufacturing and industrial settings by providing real-time object recognition, scene understanding, and navigation assistance for workers with visual impairments.\\n* **Transportation and Mobility**: Empower individuals with visual disabilities to navigate public transportation, drive with assistive devices, and explore new environments with greater confidence and independence.\\n\\n**Ethical Considerations:**\\n\\n* **Privacy and Security**: Continuously evaluate and strengthen privacy and security measures to protect user data and ensure that sensitive information is handled responsibly and in accordance with ethical guidelines and regulations.\\n* **Bias Mitigation**: Implement robust strategies to mitigate potential biases in the underlying models and algorithms, ensuring fairness and accuracy in object recognition, scene understanding, and interaction.\\n* **Responsible Marketing and Representation**: Promote the product in a way that empowers individuals with visual disabilities and avoids perpetuating stereotypes or stigmas.\\n\\n**Research and Development:**\\n\\n* **Advanced Artificial Intelligence and Machine Learning**: Explore and implement advanced artificial intelligence and machine learning techniques to enhance the accuracy, efficiency, and generalization capabilities of the product's object recognition, scene understanding, and interaction algorithms.\\n* **Multimodal Interaction and Feedback Research**: Conduct research and development on novel multimodal interaction and feedback mechanisms to provide a more intuitive, accessible, and engaging user experience.\\n* **User Experience and Accessibility Research**: Collaborate with users, researchers, and accessibility experts to continuously evaluate and improve the product's usability, accessibility, and overall user experience for individuals with diverse visual disabilities.\\n\\n**Social Impact and Advocacy:**\\n\\n* **Empowerment and Independence**: Empower individuals with visual disabilities to live more independent and fulfilling lives by providing them with the tools and knowledge to navigate and interact\", cost=({'total_cost': 0.0, 'gemini-pro': {'cost': 0.0, 'prompt_tokens': 30840, 'completion_tokens': 22, 'total_tokens': 30862}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder = AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=10,\n",
    "    description=\"I am good at writing code\",\n",
    ")\n",
    "\n",
    "pm = AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    max_consecutive_auto_reply=10,\n",
    "    description=\"I am good at design products and software.\",\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    code_execution_config={\"last_n_messages\": 20, \"work_dir\": \"coding\", \"use_docker\": False},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0,\n",
    "    description=\"I stands for user, and can run code.\",\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\": 42},\n",
    "    is_termination_msg=lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0,\n",
    ")\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"Design and implement a multimodal product for people with vision disabilities.\n",
    "The pipeline will take an image and run Gemini model to describe:\n",
    "1. what objects are in the image, and\n",
    "2. where these objects are located.\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Using Gemini with AutoGen",
   "tags": [
    "gemini"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
