# Open Source Agentics Statement

We are committed to building agentic systems that reflect humanity’s highest values—prioritizing safety, fairness, and empowerment—while addressing the inherent complexities of agentic AI and ethical decision-making. We believe in the power of open-source collaboration and agentic AI to forge a future where technology and humanity unite for shared purposes and collective flourishing.

**Open Source Agentics Core Principles**
 
- Prevent Harm: Our agentic systems are designed to detect and alert on potential harm and minimize unintended consequences.
    
Example: An agent system being adapted for military targeting or predictive policing applications triggers a critical health check via telemetry. The system flags the misuse, alerting those running the application.

- Prioritize Ethical Directives: We ensure systems can detect and alert when directives are misaligned with safety and ethical principles, always prioritizing human welfare.

Example: A triage agent in a hospital setting encounters a request to prioritize wealthy patients over others. The agent flags this request as potentially unethical, alerting human operators to ensure fair treatment.

- Maintain Integrity: Our systems are resilient and designed to detect and alert on inconsistencies that could compromise transparency and trust.

Example: An agent responsible for supply chain management detects data corruption that could lead to faulty decisions, such as overstocking harmful materials. The system alerts operators to the inconsistencies.

- Empower Human Agency: We prioritize human welfare, ensuring individuals retain control over their choices and data, while rejecting systems that commodify autonomy or labor.
    
Example: A personal assistant agent handling sensitive personal data detects attempts to manipulate user preferences or data for monetization without consent. It flags this behavior and alerts the user.

- Promote Equity: Our systems are designed to detect and alert on potential bias and prioritize societal benefit over narrow corporate interests.
        
Example: An insurance claim processing agent is found to be prioritizing low-payout cases to improve company profits. The system flags this as potentially misaligned behavior, alerting human operators to ensure fair processing.
    
**Our Commitment**

We are committed to continuous improvement and collaboration. We actively seek feedback from diverse stakeholders to ensure our systems are aligned with human values and societal needs. Rejecting cynicism, we believe that by working together, we can create a future where agentic AI benefits all of humanity.
